{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Z-bAoOArWdcz",
        "QLYBkj0CYBIv",
        "QvB6BmlLYGbt"
      ],
      "authorship_tag": "ABX9TyMwoWZzOeHzPIdX+xfVvzzW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZainaHweij/csdiagnostic/blob/main/RFC_Model_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning RFC algorithm to diagnose Acute Compartment Syndrome"
      ],
      "metadata": {
        "id": "tMMj4Ap_1ZOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train classification algorithm"
      ],
      "metadata": {
        "id": "Z-bAoOArWdcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "KLyWBITKWWOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "p7nwE5kA1X-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "fx59XmdDWprX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF_K383m0j54"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load dataset training_three.csv\n",
        "df = pd.read_csv('/content/drive/MyDrive/SEF 2023-2024/TinyML/training_three.csv')\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df[['fsr_1', 'fsr_2','fsr_3','fsr_4','fsr_5']]\n",
        "y = df['ground_truth']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Display classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save the model to a file\n",
        "model_filename = '/content/drive/MyDrive/SEF 2023-2024/TinyML/tinyml_model.pkl'\n",
        "joblib.dump(clf, model_filename)\n",
        "print(f\"Model saved to {model_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test correct csv data loading if necessary"
      ],
      "metadata": {
        "id": "rhfZGHnjW7C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test, y_pred)"
      ],
      "metadata": {
        "id": "ZiTZNtv5HJzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize model"
      ],
      "metadata": {
        "id": "aBXF9icVewHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize a decision tree in a Random Forest"
      ],
      "metadata": {
        "id": "2NSWclepeG1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have a trained Random Forest classifier named 'clf'\n",
        "# You can pick a tree, e.g., the first one (index 0)\n",
        "tree_to_visualize = clf.estimators_[0]\n",
        "\n",
        "# Convert class names to strings\n",
        "class_names_str = [str(class_name) for class_name in clf.classes_]\n",
        "\n",
        "# Plot the tree\n",
        "plt.figure(figsize=(15, 10))\n",
        "plot_tree(tree_to_visualize, filled=True, feature_names=X.columns, class_names=class_names_str, rounded=True)\n",
        "plt.title(\"Decision Tree Visualization\")\n",
        "\n",
        "save_path = '/content/drive/MyDrive/SEF 2023-2024/TinyML/Performance/RFC_model/decision_tree_RFC.png'\n",
        "plt.savefig(save_path)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZwcGjMEIdAHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize feature importance"
      ],
      "metadata": {
        "id": "hZKHGLI1gGdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = clf.feature_importances_\n",
        "plt.bar(X.columns, feature_importances)\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Importance Score')\n",
        "plt.title('Feature Importances')\n",
        "\n",
        "save_path = '/content/drive/MyDrive/SEF 2023-2024/TinyML/Performance/RFC_model/feature_importance.png'\n",
        "plt.savefig(save_path)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R0YXlzgtfBFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC Curve"
      ],
      "metadata": {
        "id": "dqMVRvW8hftX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], '--', color='gray', label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "\n",
        "save_path = '/content/drive/MyDrive/SEF 2023-2024/TinyML/Performance/RFC_model/ROC_curve.png'\n",
        "plt.savefig(save_path)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CbyQwq4dgNVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate metrics"
      ],
      "metadata": {
        "id": "QLYBkj0CYBIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Extract TP, TN, FP, FN from the confusion matrix\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Calculate sensitivity (recall), specificity, precision, and F1 score\n",
        "sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0  # Check for division by zero\n",
        "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0  # Check for division by zero\n",
        "precision = tp / (tp + fp) if (tp + fp) != 0 else 0  # Check for division by zero\n",
        "f1_score = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) != 0 else 0  # Check for division by zero\n",
        "\n",
        "print(conf_matrix)\n",
        "print(f\"\\nAccuracy: {accuracy}\")\n",
        "print(f\"Sensitivity (Recall): {sensitivity}\")\n",
        "print(f\"Specificity: {specificity}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1 Score: {f1_score}\")"
      ],
      "metadata": {
        "id": "qgW2GFkBYLGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize metrics"
      ],
      "metadata": {
        "id": "QvB6BmlLYGbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save raw metric scores accuracy, sensitivity, specificity, precision, F1 score and confusian matrix to text file\n"
      ],
      "metadata": {
        "id": "d9BIj3ovahnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_filename = '/content/drive/MyDrive/SEF 2023-2024/TinyML/Performance/RFC_model/data.txt'\n",
        "with open(output_filename, 'w') as file:\n",
        "    print(\"Confusion Matrix:\", file=file)\n",
        "    print(conf_matrix, file=file)\n",
        "    print(f\"\\nAccuracy: {accuracy}\", file=file)\n",
        "    print(f\"Sensitivity (Recall): {sensitivity}\", file=file)\n",
        "    print(f\"Specificity: {specificity}\", file=file)\n",
        "    print(f\"Precision: {precision}\", file=file)\n",
        "    print(f\"F1 Score: {f1_score}\", file=file)\n",
        "\n",
        "print(\"saved to file\")"
      ],
      "metadata": {
        "id": "dH6MR3HCaSA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix (heat map)"
      ],
      "metadata": {
        "id": "7PtG9G4McB5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Display the confusion matrix using a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Predicted Negative (0)', 'Predicted Positive (1)'],\n",
        "            yticklabels=['Actual Negative (0)', 'Actual Positive (1)'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted ACS')\n",
        "plt.ylabel('True ACS')\n",
        "\n",
        "save_path = '/content/drive/MyDrive/SEF 2023-2024/TinyML/Performance/RFC_model/CM.png'\n",
        "plt.savefig(save_path)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BeJClnKS3bzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics (bar chart)"
      ],
      "metadata": {
        "id": "rhjoaMEWcNpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_names = ['Accuracy', 'Sensitivity (Recall)', 'Specificity', 'Precision', 'F1 Score']\n",
        "metrics_values = [accuracy, sensitivity, specificity, precision, f1_score]\n",
        "\n",
        "plt.figure(figsize=(10, 5)) # Higher = better\n",
        "plt.bar(metrics_names, metrics_values, color=['skyblue', 'lightgreen', 'lightcoral', 'gold', 'orchid']) # Can select other colors\n",
        "plt.title('Model Performance Metrics')\n",
        "plt.ylabel('Score')\n",
        "\n",
        "save_path = '/content/drive/MyDrive/SEF 2023-2024/TinyML/Performance/RFC_model/PM.png'\n",
        "plt.savefig(save_path)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dDLwjFMf7-tL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}